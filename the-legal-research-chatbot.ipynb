{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10001845,"sourceType":"datasetVersion","datasetId":6156462}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain\n!pip install transformers\n!pip install sentence-transformers\n!pip install faiss-cpu\n!pip install gradio\n!pip install pdfplumber\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install faiss-cpu\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install langchain transformers sentence-transformers faiss-cpu gradio pdfplumber\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install huggingface_hub\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U langchain-community\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pdfplumber\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import HuggingFaceHub\nimport gradio as gr\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# List all directories and files in the '/kaggle/input/' folder\ndataset_root = '/kaggle/input/'\ndataset_files = os.listdir(dataset_root)\nprint(dataset_files)  # This will print the available datasets\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\npdf_folder_path = '/kaggle/input/legal-docs/'  # Folder containing the PDF files\nfiles_in_dataset = os.listdir(pdf_folder_path)\nprint(\"Files in the folder:\", files_in_dataset)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pdfplumber\n\npdf_folder_path = '/kaggle/input/legal-docs/legal_docs/'  \n\n# Function to extract text from PDFs\ndef extract_text_from_pdf(pdf_path):\n    text = \"\"\n    with pdfplumber.open(pdf_path) as pdf:\n        for page in pdf.pages:\n            text += page.extract_text()\n    return text\n\nlegal_docs = []  \npdf_files = [\"A18.pdf\", \"c-46.pdf\", \"F04P5.pdf\", \"Rules.pdf\"]  # List of your PDFs\n\nfor filename in pdf_files:\n    file_path = os.path.join(pdf_folder_path, filename)\n    if os.path.exists(file_path):  # Check if file exists\n        text = extract_text_from_pdf(file_path)\n        legal_docs.append({\"filename\": filename, \"text\": text})\n    else:\n        print(f\"File {filename} does not exist in the folder {pdf_folder_path}\")\n\n# Print the extracted legal documents\nprint(legal_docs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\n# Function to preprocess text\ndef preprocess_text(text):\n    # Removing special characters and extra spaces\n    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\n# Preprocess all extracted text\nfor doc in legal_docs:\n    doc[\"text\"] = preprocess_text(doc[\"text\"])  # Preprocess and clean the text\n\n# Preview cleaned text\nprint(f\"Preview of cleaned text from {legal_docs[0]['filename']}:\\n\")\nprint(legal_docs[0][\"text\"][:500])  # Show first 500 characters of cleaned text\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Preview of cleaned text from {legal_docs[3]['filename']}:\\n\")\nprint(legal_docs[3][\"text\"][:500])  # Show first 500 characters of cleaned text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preview extracted text from all documents\nfor doc in legal_docs:\n    print(f\"Document: {doc['filename']}\\n\")\n    print(doc['text'][:500])  # Print first 500 characters of the document text\n    print(\"\\n\" + \"-\" * 50 + \"\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to extract text from a single PDF\ndef extract_text_from_pdf(file_path):\n    with pdfplumber.open(file_path) as pdf:\n        text = \"\"\n        for page in pdf.pages:\n            text += page.extract_text()\n    return text\n\n# Example usage: Extract text from all PDFs in the 'legal_docs' folder\nimport os\n\nfolder_path = '/kaggle/input/legal-docs/legal_docs/'   \npdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n\ndocuments = [extract_text_from_pdf(pdf_file) for pdf_file in pdf_files]\nprint(f\"Extracted text from {len(documents)} documents.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Split and Embed Text\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\n\n# Example: Input documents (replace or load your actual data here)\ndocuments = [\n    {\"text\": \"Province o f Alberta ALBERTA EVIDENCE ACT Revised Statutes of Alberta 2000 Chapter A18 Current as of June 21 2024 Office Consolidation Published by Alberta Kings Printer Alberta Kings Printer Suite 700 Park Plaza 10611 98 Avenue Edmonton AB T5K 2P7 Phone 7804274952 Email kingsprintergovabca Shop online at kingsprinteralbertacaCopyright and Permission Statement The Government of Alberta through the Alberta Kings Printer holds copyright for all Alberta legislation Alberta Kings Printer permits any\"},\n    {\"text\": \"Province o f Alberta FAMILY LAW ACT Statutes of Alberta 2003 Chapter F45 Current as of April 1 2023 Office Consolidation Published by Alberta Kings Printer Alberta Kings Printer Suite 700 Park Plaza 10611 98 Avenue Edmonton AB T5K 2P7 Phone 7804274952 Email kingsprintergovabca Shop online at kingsprinteralbertacaCopyright and Permission Statement The Government of Alberta through the Alberta Kings Printer holds copyright for all Alberta legislation Alberta Kings Printer permits any person to rep\"},\n    {\"text\": \"The Rules of the Law Society of Alberta September 26 2024Law Society of Alberta The Rules of the Law Society of Alberta Amendment Table 2024V3 Amendment Amendment Amendment Other Rules Modified Description of Change Authorized Effective Source Impact To require employers with previous summer students to make any offers September 26 September 26 Bencher 492 of articling employment to those 2024 2024 Meeting students prior to the start of the articling recruitment period To amend the time at which\"},\n    {\"text\": \"CANADA CONSOLIDATION CODIFICATION Criminal Code Code criminel RSC 1985 c C46 LRC 1985 ch C46 Current to October 14 2024 jour au 14 octobre 2024 Last amended on September 18 2024 Dernire modification le 18 septembre 2024 Published by the Minister of Justice at the following address Publi par le ministre de la Justice ladresse suivante httplawsloisjusticegcca httploislawsjusticegccaOFFICIAL STATUS CARACTRE OFFICIEL OF CONSOLIDATIONS DES CODIFICATIONS Subsections 311 and 2 of the Legislation Revisi\"}]\n\n# Step 1: Extract text and split into chunks\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nsplit_documents = []\n\nfor doc in documents:\n    text = doc[\"text\"]  # Extract text if documents are dictionaries\n    chunks = text_splitter.split_text(text)\n    split_documents.extend(chunks)\n\nprint(f\"Split into {len(split_documents)} chunks.\")\n\n# Step 2: Create embeddings\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\nvector_store = FAISS.from_texts(split_documents, embeddings)\n\n# Step 3: Save or use the FAISS index\nvector_store.save_local(\"faiss_index\")\n\nprint(f\"Created vector store with {len(split_documents)} chunks.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n!pip install faiss-cpu\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Check if the file exists\nprint(os.listdir())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install faiss-cpu\n!pip install langchain\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir('faiss_index'))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\n\n# Assuming 'legal_docs' is a list of dictionaries containing your legal documents\n# For example, legal_docs could look like this:\nlegal_docs = [\n        {\"text\": \"Province o f Alberta ALBERTA EVIDENCE ACT Revised Statutes of Alberta 2000 Chapter A18 Current as of June 21 2024 Office Consolidation Published by Alberta Kings Printer Alberta Kings Printer Suite 700 Park Plaza 10611 98 Avenue Edmonton AB T5K 2P7 Phone 7804274952 Email kingsprintergovabca Shop online at kingsprinteralbertacaCopyright and Permission Statement The Government of Alberta through the Alberta Kings Printer holds copyright for all Alberta legislation Alberta Kings Printer permits any\"},\n    {\"text\": \"Province o f Alberta FAMILY LAW ACT Statutes of Alberta 2003 Chapter F45 Current as of April 1 2023 Office Consolidation Published by Alberta Kings Printer Alberta Kings Printer Suite 700 Park Plaza 10611 98 Avenue Edmonton AB T5K 2P7 Phone 7804274952 Email kingsprintergovabca Shop online at kingsprinteralbertacaCopyright and Permission Statement The Government of Alberta through the Alberta Kings Printer holds copyright for all Alberta legislation Alberta Kings Printer permits any person to rep\"},\n    {\"text\": \"The Rules of the Law Society of Alberta September 26 2024Law Society of Alberta The Rules of the Law Society of Alberta Amendment Table 2024V3 Amendment Amendment Amendment Other Rules Modified Description of Change Authorized Effective Source Impact To require employers with previous summer students to make any offers September 26 September 26 Bencher 492 of articling employment to those 2024 2024 Meeting students prior to the start of the articling recruitment period To amend the time at which\"},\n    {\"text\": \"CANADA CONSOLIDATION CODIFICATION Criminal Code Code criminel RSC 1985 c C46 LRC 1985 ch C46 Current to October 14 2024 jour au 14 octobre 2024 Last amended on September 18 2024 Dernire modification le 18 septembre 2024 Published by the Minister of Justice at the following address Publi par le ministre de la Justice ladresse suivante httplawsloisjusticegcca httploislawsjusticegccaOFFICIAL STATUS CARACTRE OFFICIEL OF CONSOLIDATIONS DES CODIFICATIONS Subsections 311 and 2 of the Legislation Revisi\"}]\n\n]\n\n# Initialize the Hugging Face embeddings model\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n\n# Split documents into chunks\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\nsplit_documents = []\n\nfor doc in legal_docs:\n    text = doc[\"text\"]\n    chunks = text_splitter.split_text(text)\n    split_documents.extend(chunks)\n\n# Create the FAISS vector store with embeddings\nvector_store = FAISS.from_texts(split_documents, embeddings)\n\n# Save the FAISS index (optional)\nvector_store.save_local('faiss_index')\n\nprint(\"FAISS index created and saved.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the number of items in the FAISS index\nprint(f\"FAISS index contains {vector_store.index.ntotal} items.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Retrieve Relevant Documents Using FAISS\n# Query to retrieve relevant documents\nquery = \"What is the basis of contract law in Alberta?\"\n\n# Perform similarity search (retrieving top 3 relevant documents)\nresults = vector_store.similarity_search(query, k=3)\n\n# Print the results\nprint(f\"Top 3 relevant document chunks for the query '{query}':\\n\")\nfor idx, result in enumerate(results):\n    print(f\"Result {idx+1}: {result}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openai\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install openai\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\n# Assume vector_store is already created with FAISS\n\n# Load the pre-trained T5 model and tokenizer from Hugging Face\nmodel_name = \"t5-small\"  # You can replace this with another model like 't5-base' or 't5-large'\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = T5Tokenizer.from_pretrained(model_name)\n\n# Define a function to generate answers based on the input text\ndef generate_answer(query, context):\n    input_text = f\"question: {query}  context: {context}\"\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n\n    # Generate the response from the model\n    outputs = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return generated_text\n\n# Query for document retrieval using FAISS\nquery = \"What is the basis of contract law in Alberta?\"\nretrieved_documents = vector_store.similarity_search(query, k=3)  # Retrieve top 3 relevant documents\n\n# Concatenate the retrieved documents' text into one context\ncontext = \" \".join([doc.page_content for doc in retrieved_documents])\n\n# Generate an answer based on the context retrieved\nanswer = generate_answer(query, context)\n\nprint(f\"Answer: {answer}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create a Gradio Interface\n!pip install gradio\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\n# Load the pre-trained T5 model and tokenizer from Hugging Face\nmodel_name = \"t5-small\"  # You can replace this with another model like 't5-base' or 't5-large'\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = T5Tokenizer.from_pretrained(model_name)\n\n# Initialize Hugging Face embeddings model for FAISS\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n\n# Define the path to your FAISS index\nfaiss_index_path = '/kaggle/input/faiss_index'  # Replace this with the actual path where your FAISS index is located\n\n# Load your FAISS vector store\nvector_store = FAISS.load_local(faiss_index_path, embeddings)\n\n# Function to generate an answer from the context (retrieved documents)\ndef generate_answer(query, context):\n    input_text = f\"question: {query}  context: {context}\"\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n\n    # Generate the response from the model\n    outputs = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return generated_text\n\n# Gradio Interface function\ndef rag_query(query):\n    # Perform similarity search using FAISS (or other retrieval method)\n    retrieved_documents = vector_store.similarity_search(query, k=3)\n\n    # Concatenate the retrieved documents' text into one context\n    context = \" \".join([doc.page_content for doc in retrieved_documents])\n\n    # Generate an answer based on the context retrieved\n    answer = generate_answer(query, context)\n    \n    return answer\n\n# Create the Gradio interface\niface = gr.Interface(\n    fn=rag_query,  # The function to call when the user submits a query\n    inputs=\"text\",  # Input is a text field\n    outputs=\"text\",  # Output will be a text response\n    live=True,  # Optional: to show results in real-time as the user types\n    title=\"RAG System for Legal Questions\",  # Title of the interface\n    description=\"Enter a legal question, and the system will retrieve relevant documents and generate an answer.\"\n)\n\n# Launch the interface\niface.launch()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\n# Load the pre-trained T5 model and tokenizer from Hugging Face\nmodel_name = \"t5-small\"  \nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = T5Tokenizer.from_pretrained(model_name)\n\n# Initialize Hugging Face embeddings model for FAISS\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n\n# Assuming you have already split your documents and embedded them\n# Example: split_documents is the list of text chunks from your documents\n# If you have your documents already, replace the below list with your actual split documents\nsplit_documents = [\n    \"Contract law in Alberta is based on common law principles.\",\n    \"Tort law often deals with negligence and liability issues.\",\n    \"Canadian business law governs the formation and operation of companies.\"\n]\n\n# Create the FAISS vector store from the split documents\nvector_store = FAISS.from_texts(split_documents, embeddings)\n\n# Function to generate an answer from the context (retrieved documents)\ndef generate_answer(query, context):\n    input_text = f\"question: {query}  context: {context}\"\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n\n    # Generate the response from the model\n    outputs = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return generated_text\n\n# Gradio Interface function\ndef rag_query(query):\n    # Perform similarity search using FAISS (or other retrieval method)\n    retrieved_documents = vector_store.similarity_search(query, k=3)\n\n    # Concatenate the retrieved documents' text into one context\n    context = \" \".join([doc.page_content for doc in retrieved_documents])\n\n    # Generate an answer based on the context retrieved\n    answer = generate_answer(query, context)\n    \n    return answer\n\n# Create the Gradio interface\niface = gr.Interface(\n    fn=rag_query,  # The function to call when the user submits a query\n    inputs=\"text\",  # Input is a text field\n    outputs=\"text\",  # Output will be a text response\n    live=True,  # Optional: to show results in real-time as the user types\n    title=\"LEGAL RESEARCH CHATBOT DEVELOPMENT USING LANGCHAIN\",  # Title of the interface\n    description=\"Enter a legal question, and the system will retrieve relevant documents and generate an answer.\"\n)\n\n# Launch the interface\niface.launch()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}